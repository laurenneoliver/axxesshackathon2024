const { GoogleGenerativeAI } = require("@google/generative-ai");
const fs = require("fs");

// Access your API key as an environment variable (see "Set up your API key" above)
const genAI = new GoogleGenerativeAI(process.env.API_KEY);

// Converts local file information to a GoogleGenerativeAI.Part object.
function fileToGenerativePart(path, mimeType) {
  return {
    inlineData: {
      data: Buffer.from(fs.readFileSync(path)).toString("base64"),
      mimeType
    },
  };
}

async function run() {
  // For text-and-image input (multimodal), use the gemini-pro-vision model
  const model = genAI.getGenerativeModel({ model: "gemini-pro-vision" });

  const prompt = "Please identify the image , if the image is not a medical image ,tell the user to click the image of a wound ,and if it is then What is the injury that you identify in the first and the second image, give me cause and treatement for each of them in an organised spaced way, if the injury looks serious give steps to handle it in the meanwhile and recommend user to visit the doctor, also give number of the nearest pharma company(for medicine)and hospital to the user , image 2 was taken in 990 Loop road southwest,richardson ";

  const imageParts = [
    fileToGenerativePart("Image1.png", "image/png"),
    fileToGenerativePart("Image5.jpg", "image/jpeg"),
  ];

  const result = await model.generateContent([prompt, ...imageParts]);
  const response = await result.response;
  const text = response.text();
  console.log(text);
}

run();
